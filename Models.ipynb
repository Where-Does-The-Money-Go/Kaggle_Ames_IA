{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function  # Python 2 and 3\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from numpy.random import shuffle\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LassoCV, ElasticNetCV\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "#from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import statsmodels.api as sm \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import decimal\n",
    "import sklearn.feature_selection as fs\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Training Set & Filter For Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour',\n",
    "                       'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n",
    "                      'Condition1', 'Condition2', 'BldgType', 'HouseStyle', \n",
    "                      'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n",
    "                       'MasVnrType',\n",
    "                       'Foundation', 'BsmtFinType1', 'BsmtFinType2',\n",
    "                       'Heating', 'CentralAir', 'Electrical', 'Functional', \n",
    "                       'GarageType', 'GarageFinish', 'PavedDrive', 'Fence',\n",
    "                       'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "drops = ['GarageArea', 'GarageYrBlt', 'Id', 'FullBath',\n",
    "         'TotRmsAbvGrd', 'X2ndFlrSF', 'BsmtFullBath',\n",
    "         'MSZoning', 'SalePrice', ]\n",
    "categorical_columns = list(filter(lambda v: v not in drops, categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>Heating</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>Functional</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>PConc</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>PConc</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.0</td>\n",
       "      <td>14115.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>PConc</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.0</td>\n",
       "      <td>10084.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1694.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1694.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>Wood</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Y</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>62.0</td>\n",
       "      <td>7917.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1647.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Somerst</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>PConc</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>85.0</td>\n",
       "      <td>13175.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>66.0</td>\n",
       "      <td>9042.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NWAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>Stone</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>Rec</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Min1</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Y</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>68.0</td>\n",
       "      <td>9717.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>CemntBd</td>\n",
       "      <td>CmentBd</td>\n",
       "      <td>None</td>\n",
       "      <td>Stone</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>75.0</td>\n",
       "      <td>9937.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Rec</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "      <td>FuseA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1409 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1    2    3       4       5      6    7    8    9   10   11  \\\n",
       "1     68.0  11250.0  7.0  5.0  2001.0  2002.0  162.0  4.0  3.0  4.0  3.0  2.0   \n",
       "2     60.0   9550.0  7.0  5.0  1915.0  1970.0    0.0  3.0  3.0  3.0  4.0  1.0   \n",
       "3     84.0  14260.0  8.0  5.0  2000.0  2000.0  350.0  4.0  3.0  4.0  3.0  3.0   \n",
       "4     85.0  14115.0  5.0  5.0  1993.0  1995.0    0.0  3.0  3.0  4.0  3.0  1.0   \n",
       "5     75.0  10084.0  8.0  5.0  2004.0  2005.0  186.0  4.0  3.0  5.0  3.0  3.0   \n",
       "...    ...      ...  ...  ...     ...     ...    ...  ...  ...  ...  ...  ...   \n",
       "1405  62.0   7917.0  6.0  5.0  1999.0  2000.0    0.0  3.0  3.0  4.0  3.0  1.0   \n",
       "1406  85.0  13175.0  6.0  6.0  1978.0  1988.0  119.0  3.0  3.0  4.0  3.0  1.0   \n",
       "1407  66.0   9042.0  7.0  9.0  1941.0  2006.0    0.0  5.0  4.0  3.0  4.0  1.0   \n",
       "1408  68.0   9717.0  5.0  6.0  1950.0  1996.0    0.0  3.0  3.0  3.0  3.0  2.0   \n",
       "1409  75.0   9937.0  5.0  6.0  1965.0  1965.0    0.0  4.0  3.0  3.0  3.0  1.0   \n",
       "\n",
       "          12      13     14      15   16      17   18      19   20   21   22  \\\n",
       "1      486.0     0.0  434.0   920.0  5.0   920.0  0.0  1786.0  1.0  3.0  4.0   \n",
       "2      216.0     0.0  540.0   756.0  4.0   961.0  0.0  1717.0  0.0  3.0  4.0   \n",
       "3      655.0     0.0  490.0  1145.0  5.0  1145.0  0.0  2198.0  1.0  4.0  4.0   \n",
       "4      732.0     0.0   64.0   796.0  5.0   796.0  0.0  1362.0  1.0  1.0  3.0   \n",
       "5     1369.0     0.0  317.0  1686.0  5.0  1694.0  0.0  1694.0  0.0  3.0  4.0   \n",
       "...      ...     ...    ...     ...  ...     ...  ...     ...  ...  ...  ...   \n",
       "1405     0.0     0.0  953.0   953.0  5.0   953.0  0.0  1647.0  1.0  3.0  3.0   \n",
       "1406   790.0   163.0  589.0  1542.0  3.0  2073.0  0.0  2073.0  0.0  3.0  3.0   \n",
       "1407   275.0     0.0  877.0  1152.0  5.0  1188.0  0.0  2340.0  0.0  4.0  4.0   \n",
       "1408    49.0  1029.0    0.0  1078.0  4.0  1078.0  0.0  1078.0  0.0  2.0  4.0   \n",
       "1409   830.0   290.0  136.0  1256.0  4.0  1256.0  0.0  1256.0  1.0  3.0  3.0   \n",
       "\n",
       "       23   24   25   26   27     28    29     30     31   32   33      34  \\\n",
       "1     1.0  3.0  2.0  3.0  3.0    0.0  42.0    0.0    0.0  0.0  0.0     0.0   \n",
       "2     1.0  4.0  3.0  3.0  3.0    0.0  35.0  272.0    0.0  0.0  0.0     0.0   \n",
       "3     1.0  3.0  3.0  3.0  3.0  192.0  84.0    0.0    0.0  0.0  0.0     0.0   \n",
       "4     0.0  0.0  2.0  3.0  3.0   40.0  30.0    0.0  320.0  0.0  0.0   700.0   \n",
       "5     1.0  4.0  2.0  3.0  3.0  255.0  57.0    0.0    0.0  0.0  0.0     0.0   \n",
       "...   ...  ...  ...  ...  ...    ...   ...    ...    ...  ...  ...     ...   \n",
       "1405  1.0  3.0  2.0  3.0  3.0    0.0  40.0    0.0    0.0  0.0  0.0     0.0   \n",
       "1406  2.0  3.0  2.0  3.0  3.0  349.0   0.0    0.0    0.0  0.0  0.0     0.0   \n",
       "1407  2.0  4.0  1.0  3.0  3.0    0.0  60.0    0.0    0.0  0.0  0.0  2500.0   \n",
       "1408  0.0  0.0  1.0  3.0  3.0  366.0   0.0  112.0    0.0  0.0  0.0     0.0   \n",
       "1409  0.0  0.0  1.0  3.0  3.0  736.0  68.0    0.0    0.0  0.0  0.0     0.0   \n",
       "\n",
       "        35      36      37  MSSubClass Street Alley LotShape LandContour  \\\n",
       "1      9.0  2008.0  2002.0        60.0   Pave  None      Reg         Lvl   \n",
       "2      2.0  2006.0  1970.0        60.0   Pave  None      IR1         Lvl   \n",
       "3     12.0  2008.0  2000.0        70.0   Pave  None      IR1         Lvl   \n",
       "4     10.0  2009.0  1995.0        60.0   Pave  None      IR1         Lvl   \n",
       "5      8.0  2007.0  2005.0        50.0   Pave  None      IR1         Lvl   \n",
       "...    ...     ...     ...         ...    ...   ...      ...         ...   \n",
       "1405   8.0  2007.0  2000.0        20.0   Pave  Pave      Reg         Lvl   \n",
       "1406   2.0  2010.0  1988.0        60.0   Pave  None      Reg         Lvl   \n",
       "1407   5.0  2010.0  2006.0        20.0   Pave  None      Reg         Lvl   \n",
       "1408   4.0  2010.0  1996.0        70.0   Pave  None      Reg         Lvl   \n",
       "1409   6.0  2008.0  1965.0        20.0   Pave  None      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope Neighborhood Condition1 Condition2  \\\n",
       "1       AllPub    Inside       Gtl      CollgCr       Norm       Norm   \n",
       "2       AllPub    Inside       Gtl      CollgCr       Norm       Norm   \n",
       "3       AllPub    Corner       Gtl      Crawfor       Norm       Norm   \n",
       "4       AllPub       FR2       Gtl      NoRidge       Norm       Norm   \n",
       "5       AllPub    Inside       Gtl      Mitchel       Norm       Norm   \n",
       "...        ...       ...       ...          ...        ...        ...   \n",
       "1405    AllPub    Inside       Gtl      Somerst       Norm       Norm   \n",
       "1406    AllPub    Inside       Gtl      Gilbert       Norm       Norm   \n",
       "1407    AllPub    Inside       Gtl       NWAmes       Norm       Norm   \n",
       "1408    AllPub    Inside       Gtl      Crawfor       Norm       Norm   \n",
       "1409    AllPub    Inside       Gtl        NAmes       Norm       Norm   \n",
       "\n",
       "     BldgType HouseStyle RoofStyle RoofMatl Exterior1st Exterior2nd  \\\n",
       "1        1Fam     2Story     Gable  CompShg     VinylSd     VinylSd   \n",
       "2        1Fam     2Story     Gable  CompShg     VinylSd     VinylSd   \n",
       "3        1Fam     2Story     Gable  CompShg     Wd Sdng     Wd Shng   \n",
       "4        1Fam     2Story     Gable  CompShg     VinylSd     VinylSd   \n",
       "5        1Fam     1.5Fin     Gable  CompShg     VinylSd     VinylSd   \n",
       "...       ...        ...       ...      ...         ...         ...   \n",
       "1405     1Fam     1Story     Gable  CompShg     VinylSd     VinylSd   \n",
       "1406     1Fam     2Story     Gable  CompShg     VinylSd     VinylSd   \n",
       "1407     1Fam     1Story     Gable  CompShg     Plywood     Plywood   \n",
       "1408     1Fam     2Story     Gable  CompShg     CemntBd     CmentBd   \n",
       "1409     1Fam     1Story       Hip  CompShg     MetalSd     MetalSd   \n",
       "\n",
       "     MasVnrType Foundation BsmtFinType1 BsmtFinType2 Heating CentralAir  \\\n",
       "1       BrkFace      PConc          GLQ          Unf    GasA          Y   \n",
       "2       BrkFace      PConc          GLQ          Unf    GasA          Y   \n",
       "3          None     BrkTil          ALQ          Unf    GasA          Y   \n",
       "4       BrkFace      PConc          GLQ          Unf    GasA          Y   \n",
       "5          None       Wood          GLQ          Unf    GasA          Y   \n",
       "...         ...        ...          ...          ...     ...        ...   \n",
       "1405       None      PConc          GLQ          Unf    GasA          Y   \n",
       "1406       None      PConc          Unf          Unf    GasA          Y   \n",
       "1407      Stone     CBlock          ALQ          Rec    GasA          Y   \n",
       "1408       None      Stone          GLQ          Unf    GasA          Y   \n",
       "1409       None     CBlock          GLQ          Rec    GasA          Y   \n",
       "\n",
       "     Electrical Functional GarageType GarageFinish PavedDrive  Fence  \\\n",
       "1         SBrkr        Typ     Attchd          RFn          Y   None   \n",
       "2         SBrkr        Typ     Attchd          RFn          Y   None   \n",
       "3         SBrkr        Typ     Detchd          Unf          Y   None   \n",
       "4         SBrkr        Typ     Attchd          RFn          Y   None   \n",
       "5         SBrkr        Typ     Attchd          Unf          Y  MnPrv   \n",
       "...         ...        ...        ...          ...        ...    ...   \n",
       "1405      SBrkr        Typ     Attchd          RFn          Y   None   \n",
       "1406      SBrkr        Typ     Attchd          RFn          Y   None   \n",
       "1407      SBrkr       Min1     Attchd          Unf          Y  MnPrv   \n",
       "1408      SBrkr        Typ     Attchd          RFn          Y  GdPrv   \n",
       "1409      FuseA        Typ     Attchd          Unf          Y   None   \n",
       "\n",
       "     MiscFeature SaleType SaleCondition  \n",
       "1           None       WD        Normal  \n",
       "2           None       WD        Normal  \n",
       "3           None       WD       Abnorml  \n",
       "4           None       WD        Normal  \n",
       "5           Shed       WD        Normal  \n",
       "...          ...      ...           ...  \n",
       "1405        None       WD        Normal  \n",
       "1406        None       WD        Normal  \n",
       "1407        None       WD        Normal  \n",
       "1408        Shed       WD        Normal  \n",
       "1409        None       WD        Normal  \n",
       "\n",
       "[1409 rows x 70 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('post_process_train.csv', index_col = 0)\n",
    "\n",
    "y = list(df['SalePrice'])\n",
    "df = df.drop(drops, axis = 1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_new = pd.concat([pd.DataFrame(fs.VarianceThreshold(threshold = .1).fit_transform(df.drop(categorical_columns, axis=1))), df[categorical_columns]], axis=1)\n",
    "df_new = df_new.drop(0, axis = 0)\n",
    "del y[0]\n",
    "df_new = df_new.drop(len(df), axis = 0)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box Cox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = scipy.stats.boxcox(y, .25)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Kaggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle = pd.read_csv('post_process_test.csv', index_col = 0).dropna()\n",
    "del drops [:-1]\n",
    "df_kaggle = df_kaggle.drop(drops, axis = 1)\n",
    "df_kaggle = pd.get_dummies(data=df_new,columns = categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_kaggle.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1409, 255)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dum = pd.get_dummies(data=df_new,columns = categorical_columns)\n",
    "df_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_dum, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##AIC & BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_add_const = sm.add_constant(X_train)\n",
    "ols = sm.OLS(y_train, X_add_const)\n",
    "ans = ols.fit()\n",
    "print(ans.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sc = StandardScaler().fit(X_train)\n",
    "#X_train = sc.transform(X_train)\n",
    "#X_test = sc.transform(X_test)\n",
    "\n",
    "mlr = linear_model.LinearRegression()\n",
    "mlr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9080591039409477"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348560230976678"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20570.260790088232"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_mae = metrics.mean_absolute_error(y_test, mlr.predict(X_test))\n",
    "mlr_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 223567832197.5207, tolerance: 576289559.4823219\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9080384446825596"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8355768598870899"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20502.371519223943"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_mae = metrics.mean_absolute_error(y_test, lasso.predict(X_test))\n",
    "lasso_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#rf = RandomForestRegressor(n_estimators = 100)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9843168518467397"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8614940539177454"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16556.458758865247"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mae = metrics.mean_absolute_error(y_test, rf.predict(X_test))\n",
    "rf_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=34, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = xgb.XGBRegressor(\n",
    "    #gamma=1,                 \n",
    "    #learning_rate=0.01,\n",
    "    #max_depth=3,\n",
    "    #n_estimators=10000,                                                                    \n",
    "    #subsample=0.8,\n",
    "    random_state=34\n",
    ") \n",
    "\n",
    "mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997299266935789"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8640302714303044"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17107.935477615247"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mae = metrics.mean_absolute_error(y_test, mod.predict(X_test))\n",
    "xgb_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.047850488553410786"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03678990769936141"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models w/ Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlrCV = linear_model.LinearRegression()\n",
    "mlr_grid_param = [{'copy_X':[True,False], 'fit_intercept': [True,False], 'n_jobs': ['None'], 'normalize':[True,False]}]\n",
    "para_search = GridSearchCV(estimator=mlrCV, param_grid=mlr_grid_param, scoring='r2', cv=5, return_train_score=True)\n",
    "para_search = para_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_copy_X', 'param_fit_intercept', 'param_n_jobs', 'param_normalize', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'mean_train_score', 'std_train_score']\n",
      "0.84614475785268\n",
      "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 'None', 'normalize': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs='None',\n",
       "                 normalize=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(para_search.cv_results_.keys()))\n",
    "para_search.cv_results_\n",
    "print(para_search.best_score_)\n",
    "print(para_search.best_params_)\n",
    "para_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9080591039409477"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_best = para_search.best_estimator_\n",
    "mlr_best.fit(X_train, y_train)\n",
    "mlr_best.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348560230976678"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20570.260790088232"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_best_mae = metrics.mean_absolute_error(y_test, mlr_best.predict(X_test))\n",
    "mlr_best_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_best = LassoCV(alphas=np.linspace(0.00001,1,1000), cv=10,tol = 0.00001,max_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196725314829.36188, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196723587864.43997, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196721861021.74496, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196720134434.45978, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196718407999.97818, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196716681716.58618, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196714955627.1872, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196713229781.98077, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196711504035.8604, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196709778554.89197, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196708053296.96585, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196706328085.65265, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196704603022.80246, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196702878245.88434, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196701153627.9472, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196699429169.50967, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196697704985.11252, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196695980812.50308, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196694256913.99304, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196692533256.75436, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196690809684.53708, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196689086395.27563, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196687363169.03134, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196685640056.67236, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196683917206.3438, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57404626.24725342, tolerance: 50863565.07850293\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196679607781.70865, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196677941714.78958, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196676224696.58087, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196674508134.00113, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196672791491.93896, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196671075305.2858, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196669359074.46335, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196667643059.79944, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196665927262.38522, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196664211609.67767, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196662496125.09396, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196660780989.49454, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196659065984.77338, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196657351016.39563, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196655636238.52856, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196653921627.8668, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196652207364.7096, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196650493134.86313, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196648779156.61142, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196647065270.7189, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196645351671.9973, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196643638153.21628, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196641924787.7966, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196640211816.88635, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196638498779.98822, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196636786028.5955, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196635073428.4439, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196633361016.8439, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195014331166.61026, tolerance: 53310912.93959524\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185034793947.06982, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185033017789.59808, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185031241959.78674, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185029466274.85175, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185027690673.87766, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185025915315.10068, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185024140138.29974, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185022365117.0265, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185020590338.16544, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185018815628.74478, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185017041135.96237, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185015266910.26868, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185013492751.64758, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185011718822.50244, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185009945121.1635, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185008171524.45865, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185006398192.89087, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185004624939.66336, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185002851827.694, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185001079066.61328, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 184999306421.33664, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 184997533840.08463, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 184995761448.54352, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 184993989382.39438, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 184992217430.3378, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 184990445591.49948, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183305144852.36426, tolerance: 50585673.179269895\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203225248442.85397, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203223515204.5461, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203221782144.08813, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203220049089.8634, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203218316263.00357, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203216583661.95068, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203214851338.67767, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203213118999.79526, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203211386967.54895, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203209655050.18204, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203207923368.39352, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203206191760.86734, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203204460387.56232, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203202729189.36258, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203200998164.72122, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203199267313.86188, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203197536606.07703, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203195806193.15845, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203194075760.1651, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203192345621.06104, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203190615634.58197, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203188885850.16556, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203187156166.6773, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203185426705.16162, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203183697353.42758, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203181968264.8798, tolerance: 53397332.23071488\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198674271671.20572, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198672608218.69403, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198670943873.77014, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198669279439.62698, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198667615447.51373, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198665951546.09674, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198664287797.11523, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198662624174.5386, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198660960884.52335, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198659297684.6467, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198657634707.58035, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198655971759.74182, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198654309033.1956, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198652646554.19135, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198650984260.2958, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198649322030.01413, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198647660057.7872, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198645998160.2712, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198644336533.2426, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198642675199.93787, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198641013794.0713, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198639352669.20798, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198637691753.08496, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198636030958.10114, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198634370309.14914, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198632709867.5018, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2689592329.8624268, tolerance: 51805262.14021334\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197278195669.0178, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197276558160.7992, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197274920798.32687, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197273283625.45447, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197271646665.4482, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197270009905.6618, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197268373211.8631, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197266736740.48566, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197265100525.89575, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197263464420.60278, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197261828423.92587, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197260192695.18164, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197258557130.4942, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197256921742.52808, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197255286530.0575, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197253651516.0807, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197252016688.7117, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197250381944.8887, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197248747398.94003, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197247113106.64542, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197245478920.6052, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197243844930.67514, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197242211057.47134, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197240577460.4723, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197238943990.688, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197237310601.4076, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195684589028.36804, tolerance: 51860616.438573726\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191364324225.42938, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191362811970.0087, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191361239499.1867, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191359667372.3848, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191358095296.31528, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191356523437.39365, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191354951702.2777, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191353380247.57434, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191351808915.35214, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191350237694.51767, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191348666669.16357, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191347095818.62277, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191345525247.12592, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191343954680.4381, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191342384509.74237, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191340814342.39447, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191339244401.20377, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191337674579.09213, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191336105015.11102, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191334535590.38254, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191332966316.94684, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191331397246.4248, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191329828272.88406, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191328259555.4509, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191326690976.6966, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191325122579.30972, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189835858685.17258, tolerance: 51740258.30732165\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206143049960.4794, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206141465105.11288, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206139880589.68158, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206138296030.73715, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206136711699.00055, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206135127560.3949, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206133543682.32135, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206131959837.6787, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206130376275.32324, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206128792848.5029, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206127209715.56113, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206125626649.22867, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206124043795.87744, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206122461121.81418, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206120878649.70795, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206119296288.06067, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206117714162.28934, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206116132168.27737, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206114550318.11676, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206112968736.6761, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206111387275.77484, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206109806014.68066, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206108224999.23672, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206106643987.7636, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206105063371.01367, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206103482815.38953, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206101902469.78363, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2964384194.8754272, tolerance: 52712111.33891964\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196558305743.76572, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196556528568.31546, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196554751596.09167, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196552974773.5142, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196551198060.3726, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196549421751.36673, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196547645309.68103, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196545869244.17917, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196544093393.99295, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196542317584.6234, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196540541976.65283, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196538766489.41525, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196536991337.30582, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196535216278.05722, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196533441311.0568, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196531666625.63907, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196529892018.4977, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196528117705.38278, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196526343388.47455, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196524569378.82867, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196522795541.51544, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196521021889.22058, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196519248366.92798, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196517474974.83264, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196515701835.00183, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194818286962.2265, tolerance: 50784829.93399915\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193080975399.57983, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193079323119.46878, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193077671189.06088, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193076019368.10138, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193074367745.10907, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193072716218.494, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193071064952.73212, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193069413909.17462, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193067762909.3968, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193066112157.59613, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193064461512.99304, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193062811077.4732, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193061160747.57544, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193059510766.76556, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193057860725.22006, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193056211071.1829, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193054561368.5957, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193052912065.30997, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193051262763.91495, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193049613668.88235, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193047964768.21747, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193046316048.06747, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193044667404.85266, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193043018980.59213, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191465969467.1249, tolerance: 51558529.22462539\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9080384600855046   test: 0.8355782383101199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nates\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 223851888536.708, tolerance: 57628955.94823218\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "L=lasso_best.fit(X_train, y_train)\n",
    "print('train:',lasso.score(X_train, y_train),'  test:',lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20502.25581183185"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_best_mae = metrics.mean_absolute_error(y_test, lasso_best.predict(X_test))\n",
    "lasso_best_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_para_tree = [{\n",
    "    \"criterion\": [\"mse\"],\n",
    "    \"max_depth\": np.linspace(start = 1, stop = 15, num = 4, dtype = int ),\n",
    "    \"min_samples_split\": np.linspace(start=2, stop=30, num=5, dtype=int),\n",
    "    \"n_estimators\": np.linspace(start = 80, stop = 120, num = 8, dtype = int )\n",
    "}]\n",
    "#tree_model.set_params(random_state=34)\n",
    "grid_search_rf = GridSearchCV(rf, grid_para_tree, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_rf = para_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9080591039409477"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.score(X_train, y_train)\n",
    "#Make your grid coarse\n",
    "#Run your first parameter, then creep up the workload\n",
    "#Bayesian Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348560230976678"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20570.260790088232"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_mae = metrics.mean_absolute_error(y_test, grid_search_rf.predict(X_test))\n",
    "rf_best_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now XG Boost w/ CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspiration for this approach from https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:linear',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mae-mean</th>\n",
       "      <th>train-mae-std</th>\n",
       "      <th>test-mae-mean</th>\n",
       "      <th>test-mae-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125138.326563</td>\n",
       "      <td>1078.742225</td>\n",
       "      <td>125353.090625</td>\n",
       "      <td>4721.924686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88378.856250</td>\n",
       "      <td>778.723453</td>\n",
       "      <td>88611.865625</td>\n",
       "      <td>3558.079023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62562.446094</td>\n",
       "      <td>565.039877</td>\n",
       "      <td>63252.411719</td>\n",
       "      <td>2785.816612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44372.863281</td>\n",
       "      <td>429.569311</td>\n",
       "      <td>46048.371875</td>\n",
       "      <td>2283.552664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31729.616797</td>\n",
       "      <td>283.775391</td>\n",
       "      <td>34624.373828</td>\n",
       "      <td>1545.833123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22960.808594</td>\n",
       "      <td>250.469364</td>\n",
       "      <td>27506.219141</td>\n",
       "      <td>1320.132565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17074.887500</td>\n",
       "      <td>249.079909</td>\n",
       "      <td>23076.301562</td>\n",
       "      <td>1091.254156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13191.478906</td>\n",
       "      <td>199.720412</td>\n",
       "      <td>20593.310156</td>\n",
       "      <td>1023.148764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10716.180469</td>\n",
       "      <td>221.823812</td>\n",
       "      <td>19113.038672</td>\n",
       "      <td>862.710450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9078.620703</td>\n",
       "      <td>197.908032</td>\n",
       "      <td>18320.957422</td>\n",
       "      <td>850.567256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8028.534277</td>\n",
       "      <td>174.924530</td>\n",
       "      <td>17901.662109</td>\n",
       "      <td>862.810203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7275.064062</td>\n",
       "      <td>188.943519</td>\n",
       "      <td>17661.956641</td>\n",
       "      <td>820.535910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6714.116211</td>\n",
       "      <td>154.489509</td>\n",
       "      <td>17464.395703</td>\n",
       "      <td>797.741328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6301.471094</td>\n",
       "      <td>154.833945</td>\n",
       "      <td>17331.974414</td>\n",
       "      <td>835.430607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5932.254492</td>\n",
       "      <td>179.382212</td>\n",
       "      <td>17265.276953</td>\n",
       "      <td>808.683775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5669.176563</td>\n",
       "      <td>179.481545</td>\n",
       "      <td>17218.811523</td>\n",
       "      <td>813.111743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5421.426660</td>\n",
       "      <td>121.724868</td>\n",
       "      <td>17249.245508</td>\n",
       "      <td>813.652896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5195.513379</td>\n",
       "      <td>129.551067</td>\n",
       "      <td>17211.700586</td>\n",
       "      <td>791.855566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5004.205762</td>\n",
       "      <td>147.645788</td>\n",
       "      <td>17189.395312</td>\n",
       "      <td>789.790318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
       "0    125138.326563    1078.742225  125353.090625   4721.924686\n",
       "1     88378.856250     778.723453   88611.865625   3558.079023\n",
       "2     62562.446094     565.039877   63252.411719   2785.816612\n",
       "3     44372.863281     429.569311   46048.371875   2283.552664\n",
       "4     31729.616797     283.775391   34624.373828   1545.833123\n",
       "5     22960.808594     250.469364   27506.219141   1320.132565\n",
       "6     17074.887500     249.079909   23076.301562   1091.254156\n",
       "7     13191.478906     199.720412   20593.310156   1023.148764\n",
       "8     10716.180469     221.823812   19113.038672    862.710450\n",
       "9      9078.620703     197.908032   18320.957422    850.567256\n",
       "10     8028.534277     174.924530   17901.662109    862.810203\n",
       "11     7275.064062     188.943519   17661.956641    820.535910\n",
       "12     6714.116211     154.489509   17464.395703    797.741328\n",
       "13     6301.471094     154.833945   17331.974414    835.430607\n",
       "14     5932.254492     179.382212   17265.276953    808.683775\n",
       "15     5669.176563     179.481545   17218.811523    813.111743\n",
       "16     5421.426660     121.724868   17249.245508    813.652896\n",
       "17     5195.513379     129.551067   17211.700586    791.855566\n",
       "18     5004.205762     147.645788   17189.395312    789.790318"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_params = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=999,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best params: 9, MAE: 17569.5267578\n"
     ]
    }
   ],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth in range(9,12):\n",
    "    params['max_depth'] = max_depth\n",
    "    # Run CV\n",
    "    cv_params = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_params['test-mae-mean'].min()\n",
    "    boost_rounds = cv_params['test-mae-mean'].argmin()\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth)\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best params: 12, MAE: 16660.1591798\n"
     ]
    }
   ],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for min_child_weight in range(3,15):\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_params = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_params['test-mae-mean'].min()\n",
    "    boost_rounds = cv_params['test-mae-mean'].argmin()\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (min_child_weight)\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['min_child_weight'] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "[14:22:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:22:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:22:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:22:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:22:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "0.5\n",
      "[14:22:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:22:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:22:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:22:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:22:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "0.6\n",
      "[14:23:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "[14:23:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "0.8\n",
      "[14:23:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "0.9\n",
      "[14:23:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: 0.4, MAE: 16660.1591798\n"
     ]
    }
   ],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for subsample_bytree in range(4,10):\n",
    "    subsample_bytree = subsample_bytree/10.0\n",
    "    print(subsample_bytree)\n",
    "    params['subsample_bytree'] = subsample_bytree\n",
    "    \n",
    "   \n",
    "    # Run CV\n",
    "    cv_params = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "     #Update best MAE\n",
    "    mean_mae = cv_params['test-mae-mean'].min()\n",
    "    boost_rounds = cv_params['test-mae-mean'].argmin()\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample_bytree)\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample_bytree'] = best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:23:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:23:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample, subsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Best params: 0.3, MAE: 16660.1591798\n"
     ]
    }
   ],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for colsample in range(3,10):\n",
    "    colsample = colsample/10.\n",
    "    params['colsample'] = colsample\n",
    "    # Run CV\n",
    "    cv_params = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_params['test-mae-mean'].min()\n",
    "    boost_rounds = cv_params['test-mae-mean'].argmin()\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (colsample)\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'min_child_weight': 12,\n",
       " 'subsample': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'objective': 'reg:linear',\n",
       " 'subsample_bytree': 0.4,\n",
       " 'colsample': 0.3}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['colsample'] = best_params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_best = xgb.XGBRegressor(\n",
    "    max_depth=params['max_depth'],                 \n",
    "    min_child_weight=params['min_child_weight'],\n",
    "    subsample = params['subsample'],\n",
    "    colsample = params['colsample_bytree'],\n",
    "    n_estimators=10000                                                                    \n",
    "    \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999999997797"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best.fit(X_train, y_train)\n",
    "mod_best.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8688921943884749"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16874.399656471633"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best_mae = metrics.mean_absolute_error(y_test, mod_best.predict(X_test))\n",
    "mod_best_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undo Box Cox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = scipy.special.inv_boxcox(y_test, 0.25)\n",
    "#Undo both or y test only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_best.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
